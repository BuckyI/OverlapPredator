from typing import Dict, List

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F

from lib.utils import square_distance
from models.blocks import block_decider
from models.gcn import GCN


class KPFCNN(nn.Module):

    def __init__(self, config):
        super(KPFCNN, self).__init__()

        ############
        # Parameters
        ############
        # Current radius of convolution and feature dimension
        layer = 0
        r = config.first_subsampling_dl * config.conv_radius
        in_dim = config.in_feats_dim  # NOTE: é…ç½®æ–‡ä»¶ä¸­è¯¥å€¼ä¸º 1 ï¼ˆä¸æ˜¯ç‰¹åˆ«æ˜ç™½ä¸ºä»€ä¹ˆç»´åº¦ä¸º 1ï¼‰#TODO
        # NOTE: è¯¥å˜é‡å­˜å‚¨äº†å½“å‰ç½‘ç»œæœ€åä¸€å±‚ï¼Œè¾“å…¥çš„ç‰¹å¾ç»´åº¦æ•°ï¼Œéšç€ç½‘ç»œå±‚çš„è§£æè€Œæ›´æ–°
        out_dim = config.first_feats_dim  # ç¬¬ä¸€å±‚è¾“å‡ºçš„ç‰¹å¾ç»´åº¦
        # NOTE: è¯¥å˜é‡å­˜å‚¨äº†å½“å‰ç½‘ç»œæœ€åä¸€å±‚ï¼Œè¾“å‡ºçš„ç‰¹å¾ç»´åº¦æ•°ï¼Œéšç€ç½‘ç»œå±‚çš„è§£æè€Œæ›´æ–°

        self.K = config.num_kernel_points
        self.epsilon = torch.nn.Parameter(torch.tensor(-5.0))
        self.final_feats_dim = config.final_feats_dim  # æœ€åä¸€å±‚è¾“å‡ºçš„ç‰¹å¾ç»´åº¦

        # NOTE: ä¸¤ä¸ªç”¨äºæ¶ˆèå®éªŒçš„å‚æ•°ï¼Œé»˜è®¤éƒ½ä¸º Trueï¼Œè¯¦è§ forward ç›¸å…³ä»£ç 
        self.condition: bool = config.condition_feature  # True
        self.add_cross_overlap: bool = config.add_cross_score  # True

        #####################
        # List Encoder blocks
        #####################
        # Save all block operations in a list of modules
        self.encoder_blocks = nn.ModuleList()
        self.encoder_skip_dims = []
        self.encoder_skips = []

        # Loop over consecutive blocks
        for block_i, block in enumerate(config.architecture):

            # Check equivariance
            # NOTE: æœ¬è®ºæ–‡è®¾è®¡çš„ç½‘ç»œæ¶æ„ä¸­ï¼Œå¹¶æ²¡æœ‰ä½¿ç”¨åˆ°åå­—åŒ…å« equivariant çš„ block (configs/models.py)
            if ("equivariant" in block) and (not out_dim % 3 == 0):
                raise ValueError("Equivariant block but features dimension is not a factor of 3")

            # Detect change to next layer for skip connection
            # NOTE: Encoder æ¯ä¸€å±‚çš„æœ€åä¸€å°å±‚è¾“å‡º skip connection
            if np.any([tmp in block for tmp in ["pool", "strided", "upsample", "global"]]):
                self.encoder_skips.append(block_i)
                self.encoder_skip_dims.append(in_dim)

            # Detect upsampling block to stop
            # NOTE: è¿™å—ä»£ç åªå¤„ç† Encoder éƒ¨åˆ†çš„å±‚ï¼Œæ‰€ä»¥é‡åˆ°ä¸Šé‡‡æ ·ï¼ˆDecoderå±‚ï¼‰å°±è·³å‡ºå¾ªç¯
            if "upsample" in block:
                break

            # Apply the good block function defining tf ops
            self.encoder_blocks.append(block_decider(block, r, in_dim, out_dim, layer, config))

            # Update dimension of input from output
            if "simple" in block:
                in_dim = out_dim // 2
            else:
                in_dim = out_dim

            # Detect change to a subsampled layer
            if "pool" in block or "strided" in block:
                # Update radius and feature dimension for next layer
                layer += 1  # strided è¡¨ç¤ºè¿™æ˜¯å½“å‰å±‚çš„æœ€åä¸€å°å±‚ï¼ˆstrided conv ä¸ºæ± åŒ–æ“ä½œï¼‰
                r *= 2  # åŠå¾„æ‰©å¤§
                out_dim *= 2  # ç‚¹ç‰¹å¾ç»´åº¦åŠ å€ 128 -> 256 -> 512

        #####################
        # bottleneck layer and GNN part
        #####################
        gnn_feats_dim = config.gnn_feats_dim
        self.bottle = nn.Conv1d(in_dim, gnn_feats_dim, kernel_size=1, bias=True)
        k = config.dgcnn_k
        num_head = config.num_head

        # NOTE: self-attention -> cross-attention -> self-attention
        self.gnn = GCN(num_head, gnn_feats_dim, k, config.nets)

        # NOTE: gnn è¾“å‡ºç‰¹å¾åˆé€šè¿‡äº†ä¸¤ä¸ª 1Ã—1 å·ç§¯
        self.proj_gnn = nn.Conv1d(gnn_feats_dim, gnn_feats_dim, kernel_size=1, bias=True)
        self.proj_score = nn.Conv1d(gnn_feats_dim, 1, kernel_size=1, bias=True)

        #####################
        # List Decoder blocks
        #####################
        if self.add_cross_overlap:
            out_dim = gnn_feats_dim + 2
        else:
            out_dim = gnn_feats_dim + 1

        # Save all block operations in a list of modules
        self.decoder_blocks = nn.ModuleList()
        self.decoder_concats = []

        # NOTE: æ„Ÿè§‰å‚æ•°è®¾è®¡ä¸Šï¼Œåº”è¯¥æŠŠç¼–ç å™¨å’Œè§£ç å™¨åˆ†åˆ«ä¼ å…¥ï¼Œå°±ä¸éœ€è¦è¿™ä¹ˆéº»çƒ¦åœ°è¿›è¡Œåˆ¤æ–­äº†ã€‚
        # Find first upsampling block
        start_i = 0
        for block_i, block in enumerate(config.architecture):
            if "upsample" in block:
                start_i = block_i
                break

        # Loop over consecutive blocks
        for block_i, block in enumerate(config.architecture[start_i:]):

            # Add dimension of skip connection concat
            if block_i > 0 and "upsample" in config.architecture[start_i + block_i - 1]:
                in_dim += self.encoder_skip_dims[layer]
                self.decoder_concats.append(block_i)

            # Apply the good block function defining tf ops
            self.decoder_blocks.append(block_decider(block, r, in_dim, out_dim, layer, config))

            # Update dimension of input from output
            in_dim = out_dim

            # Detect change to a subsampled layer
            if "upsample" in block:
                # Update radius and feature dimension for next layer
                layer -= 1
                r *= 0.5
                out_dim = out_dim // 2
        return

    def regular_score(self, score):
        "NOTE: æŠŠ score ä¸­çš„ nan å’Œ inf éƒ½æ›¿æ¢ä¸º 0"
        score = torch.where(torch.isnan(score), torch.zeros_like(score), score)
        score = torch.where(torch.isinf(score), torch.zeros_like(score), score)
        return score

    def forward(self, batch):
        # Get input features
        x = batch["features"].clone().detach()  # NOTE: è·å¾—ä¸€ä¸ªä¸è·Ÿè¸ªæ¢¯åº¦çš„å‰¯æœ¬
        len_src_c = batch["stack_lengths"][-1][0]
        len_src_f = batch["stack_lengths"][0][0]
        pcd_c = batch["points"][-1]  # NOTE: å–å‡ºçš„æœ€åä¸€å±‚çš„ç‚¹äº‘ï¼Œè¿™éƒ¨åˆ†ç”¨åœ¨äº† gnn é‚£éƒ¨åˆ†
        pcd_f = batch["points"][0]
        # NOTE: è¿™ä¸¤ä¸ª pcd æ˜¯ Encoder æœ€åä¸€å±‚æœ€ç¨€ç–çš„ç‚¹äº‘ï¼Œå–å‡ºæ¥ä½œä¸º gnn é‚£éƒ¨åˆ†çš„è¾“å…¥
        src_pcd_c, tgt_pcd_c = pcd_c[:len_src_c], pcd_c[len_src_c:]

        sigmoid = nn.Sigmoid()
        #################################
        # 1. joint encoder part
        skip_x = []
        for block_i, block_op in enumerate(self.encoder_blocks):
            if block_i in self.encoder_skips:
                skip_x.append(x)  # NOTE: ä¿å­˜å½“å‰å±‚è¾“å‡ºç”¨äº skip link
            x = block_op(x, batch)
        # NOTE: (ä»¥ indoor.yaml model ç»“æ„ä¸ºä¾‹) Encoderï¼Œæœ‰ 4 å±‚ï¼Œæ¯ä¸€å±‚éƒ½æœ‰ 3 å°å±‚
        # è¿™é‡Œ self.encoder_blocks å…±æœ‰ 11 ä¸ªå…ƒç´ ï¼Œæ˜¯å› ä¸ºæœ€åä¸€å°å±‚å®é™…ä¸Šæ˜¯ self.bottle è¿›è¡Œäº†é™ç»´
        # self.encoder_skips = [2, 5, 8, 11]

        # NOTE: Encoder è·å–åˆ°çš„ç‚¹äº‘ç‰¹å¾ï¼š
        # ğŸŒŸ skip_x[0] --> torch.Size([69778, 128])
        # ğŸŒŸ skip_x[1] --> torch.Size([6563, 256])
        # ğŸŒŸ skip_x[2] --> torch.Size([1995, 512])
        # ğŸŒŸ ç¬¬å››å±‚ç‰¹å¾ unconditioned_feats --> torch.Size([606, 256])
        # [p.shape for p in batch["points"]] --> æ¯å±‚ç‚¹äº‘ç‚¹æ•°åˆ†åˆ«ä¸ºï¼š69778, 6563, 1995, 606

        #################################
        # 2. project the bottleneck features
        feats_c = x.transpose(0, 1).unsqueeze(0)  # [1, C, N] # NOTE: è°ƒæ•´æ•°æ®ç»“æ„ä»¥é€‚ç”¨äº Conv1d
        feats_c = self.bottle(feats_c)  # [1, C, N]
        unconditioned_feats = feats_c.transpose(1, 2).squeeze(0)  # NOTE: æ²¡æœ‰ç»è¿‡ GNN çš„ç‰¹å¾ [N, C]

        #################################
        # 3. apply GNN to communicate the features and get overlap score
        src_feats_c, tgt_feats_c = feats_c[:, :, :len_src_c], feats_c[:, :, len_src_c:]
        # NOTE: è¿™é‡Œä¼ å…¥çš„ src_feats_c å’Œ tgt_feats_c æ˜¯ Encoder æœ€åä¸€å±‚ç‚¹äº‘çš„åæ ‡
        # å‰é¢ä¸ç”¨ä¼ å…¥ï¼Œæ˜¯å› ä¸º KPConv çš„å±‚ä¼šè‡ªå·±è¯»å–å¯¹åº”å±‚çš„ç‚¹äº‘ã€‚
        src_feats_c, tgt_feats_c = self.gnn(
            src_pcd_c.unsqueeze(0).transpose(1, 2),
            tgt_pcd_c.unsqueeze(0).transpose(1, 2),
            src_feats_c,
            tgt_feats_c,
        )
        feats_c = torch.cat([src_feats_c, tgt_feats_c], dim=-1)

        # NOTE: ä¸‹é¢è¿™ä¿©éƒ½æ˜¯ 1x1 å·ç§¯
        feats_c = self.proj_gnn(feats_c)  # æ²¡æœ‰æ”¹å˜ç»´åº¦ï¼Œå¯ä»¥å½“åš gnn è¾“å‡ºçš„æœ€ç»ˆç‰¹å¾ 256 (1, 256, N)
        scores_c = self.proj_score(feats_c)  # ç‰¹å¾ä» 256 åˆ° 1, ç”¨æ¥é¢„æµ‹ score (1, 1, N)

        feats_gnn_norm = (
            F.normalize(feats_c, p=2, dim=1).squeeze(0).transpose(0, 1)
        )  # [N, C], [N, 256] # NOTE: ç‰¹å¾çš„é€šé“è¿›è¡Œå½’ä¸€åŒ–å¤„ç†
        # NOTE: ğŸŒŸ GNN è¾“å‡ºç‰¹å¾
        feats_gnn_raw = feats_c.squeeze(0).transpose(0, 1)  # [N, C]
        scores_c_raw = scores_c.squeeze(0).transpose(0, 1)  # [N, 1]

        ####################################
        # 4. decoder part
        # NOTE: å‡ºäºæŸç§åŸå› ï¼Œ Decoder å¯¹ gnn è¾“å‡ºçš„ç‰¹å¾è¿›è¡Œäº†å½’ä¸€åŒ–
        src_feats_gnn, tgt_feats_gnn = feats_gnn_norm[:len_src_c], feats_gnn_norm[len_src_c:]
        # NOTE: ç‰¹å¾ç‚¹ç§¯è·å¾—ç›¸ä¼¼åº¦ (N1, C) @ (N2, C)^T -> (N_1, N_2)
        inner_products = torch.matmul(src_feats_gnn, tgt_feats_gnn.transpose(0, 1))

        src_scores_c, tgt_scores_c = scores_c_raw[:len_src_c], scores_c_raw[len_src_c:]

        # NOTE: åº”è¯¥æ˜¯å¯¹ç›¸ä¼¼åº¦çš„åˆ†å¸ƒè¿›è¡Œè°ƒæ•´ï¼Œå› ä¸º softmax å¯¹è¾ƒå¤§çš„è¾“å…¥å€¼æ— æ³•åŒºåˆ†
        temperature = torch.exp(self.epsilon) + 0.03
        # NOTE: F.softmax https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html
        # inner_products (N_1, N_2) ä»£è¡¨äº†ç‰¹å¾çš„ç›¸ä¼¼åº¦
        # Softmax å°†ç›¸ä¼¼åº¦è½¬åŒ–ä¸º 0-1 çš„æ¦‚ç‡åˆ†å¸ƒï¼Œæ²¿ç€ dim=1ï¼Œä¹Ÿå°±æ˜¯è¯´æ¯ä¸€è¡Œä¹‹å’Œä¸º 1
        # ä¸€è¡Œ N_2 ä¸ªæ•°ï¼Œä¸º tgt çš„ç‚¹æ•°ï¼Œä»£è¡¨äº†å½“å‰ src çš„ç‚¹æœ€æœ‰å¯èƒ½å’Œ tgt çš„å“ªä¸ªç‚¹åŒ¹é…
        # æœ€ååˆå’Œ tgt_scores_c è¿›è¡ŒçŸ©é˜µç›¸ä¹˜ï¼Œè·å¾—çš„ç»“æœå°±è¡¨ç¤ºäº†ï¼š**ç‰¹å¾ç›¸ä¼¼å¹¶ä¸”é‡å çš„æ¦‚ç‡**
        s1 = torch.matmul(F.softmax(inner_products / temperature, dim=1), tgt_scores_c)
        s2 = torch.matmul(F.softmax(inner_products.transpose(0, 1) / temperature, dim=1), src_scores_c)
        # NOTE: æ€»ç»“æ¥è¯´ï¼Œscores_saliency æ˜¯é€šè¿‡æ¨¡å‹é¢„æµ‹çš„ overlap score åŠ æƒå¾—åˆ°çš„ï¼Œæƒé‡æ¥è‡ªäº src å’Œ tgt æ¨¡å‹ç¼–ç ç‰¹å¾çš„ç›¸ä¼¼åº¦
        scores_saliency = torch.cat((s1, s2), dim=0)  # [N, 1]

        # NOTE: RECALL:
        # scores_c_raw          é‡å åˆ†æ•°
        # scores_saliency       åŒ¹é…åˆ†æ•°
        # feats_gnn_raw         ç»è¿‡ GNN çš„ç‚¹äº‘ç‰¹å¾
        # unconditioned_feats   æ²¡æœ‰ç»è¿‡ GNN çš„ç‰¹å¾ï¼ˆä¸åŒ…å«ä¸¤ä¸ªç‚¹äº‘ä¹‹é—´çš„å…³è”ï¼‰
        # NOTE: condition å«ä¹‰ç±»ä¼¼â€œå¯¹é½â€ï¼Œæ§åˆ¶æ˜¯å¦é€‰æ‹©ç”¨ attention æ¥è®©ä¸¤ä¸ªç‚¹äº‘çš„ç‰¹å¾äº¤äº’
        # NOTE: add_cross_overlap çš„å«ä¹‰åº”è¯¥æ˜¯ï¼Œæ˜¯å¦æŠŠåŒ¹é…åˆ†æ•°ï¼ˆcross overlap scoreï¼‰è¾“å‡ºåˆ°æœ€ç»ˆçš„ç‚¹äº‘ç‰¹å¾ä¸­
        if self.condition and self.add_cross_overlap:
            x = torch.cat([scores_c_raw, scores_saliency, feats_gnn_raw], dim=1)
        elif self.condition and not self.add_cross_overlap:
            x = torch.cat([scores_c_raw, feats_gnn_raw], dim=1)
        elif not self.condition and self.add_cross_overlap:
            x = torch.cat([scores_c_raw, scores_saliency, unconditioned_feats], dim=1)
        elif not self.condition and not self.add_cross_overlap:
            x = torch.cat([scores_c_raw, unconditioned_feats], dim=1)

        for block_i, block_op in enumerate(self.decoder_blocks):
            if block_i in self.decoder_concats:
                x = torch.cat([x, skip_x.pop()], dim=1)
            x = block_op(x, batch)
        feats_f = x[:, : self.final_feats_dim]
        scores_overlap = x[:, self.final_feats_dim]
        scores_saliency = x[:, self.final_feats_dim + 1]

        # safe guard our score
        scores_overlap = torch.clamp(sigmoid(scores_overlap.view(-1)), min=0, max=1)
        scores_saliency = torch.clamp(sigmoid(scores_saliency.view(-1)), min=0, max=1)
        scores_overlap = self.regular_score(scores_overlap)
        scores_saliency = self.regular_score(scores_saliency)

        # normalise point-wise features
        feats_f = F.normalize(feats_f, p=2, dim=1)

        return feats_f, scores_overlap, scores_saliency

    @torch.inference_mode()
    def forward_with_superpoint(self, batch):
        "ç®€åŒ– forward ä»£ç ï¼Œè°ƒæ•´è¿”å›å€¼ï¼ŒåŒæ—¶é¢å¤–è¿”å›æœªç»è¿‡ç‚¹äº‘ä¿¡æ¯äº¤äº’çš„ superpoint ç‰¹å¾"
        # Get input features
        x = batch["features"].clone().detach()

        #################################
        # 1. joint encoder part
        skip_x = []
        for block_i, block_op in enumerate(self.encoder_blocks):
            if block_i in self.encoder_skips:
                skip_x.append(x)  # NOTE: ä¿å­˜å½“å‰å±‚è¾“å‡ºç”¨äº skip link
            x = block_op(x, batch)

        #################################
        # 2. project the bottleneck features
        feats_c = x.transpose(0, 1).unsqueeze(0)  # [1, C, N] # NOTE: è°ƒæ•´æ•°æ®ç»“æ„ä»¥é€‚ç”¨äº Conv1d
        feats_c = self.bottle(feats_c)  # [1, C, N]
        unconditioned_feats = feats_c.transpose(1, 2).squeeze(0)  # NOTE: æ²¡æœ‰ç»è¿‡ GNN çš„ç‰¹å¾ [N, C]

        #################################
        # 3. apply GNN to communicate the features and get overlap score
        len_src_c = batch["stack_lengths"][-1][0]  # æœ€åä¸€å±‚ç‚¹äº‘é•¿åº¦
        src_feats_c, tgt_feats_c = feats_c[:, :, :len_src_c], feats_c[:, :, len_src_c:]
        # æœ€åä¸€å±‚ç‚¹äº‘åæ ‡
        pcd_c = batch["points"][-1]
        src_pcd_c, tgt_pcd_c = pcd_c[:len_src_c], pcd_c[len_src_c:]
        src_feats_c, tgt_feats_c = self.gnn(
            src_pcd_c.unsqueeze(0).transpose(1, 2),
            tgt_pcd_c.unsqueeze(0).transpose(1, 2),
            src_feats_c,
            tgt_feats_c,
        )
        feats_c = torch.cat([src_feats_c, tgt_feats_c], dim=-1)

        # NOTE: ä¸‹é¢è¿™ä¿©éƒ½æ˜¯ 1x1 å·ç§¯
        feats_c = self.proj_gnn(feats_c)  # æ²¡æœ‰æ”¹å˜ç»´åº¦ï¼Œå¯ä»¥å½“åš gnn è¾“å‡ºçš„æœ€ç»ˆç‰¹å¾ 256 (1, 256, N)
        scores_c = self.proj_score(feats_c)  # ç‰¹å¾ä» 256 åˆ° 1, ç”¨æ¥é¢„æµ‹ score (1, 1, N)

        feats_gnn_norm = (
            F.normalize(feats_c, p=2, dim=1).squeeze(0).transpose(0, 1)
        )  # [N, C], [N, 256] # NOTE: ç‰¹å¾çš„é€šé“è¿›è¡Œå½’ä¸€åŒ–å¤„ç†
        # NOTE: ğŸŒŸ GNN è¾“å‡ºç‰¹å¾
        feats_gnn_raw = feats_c.squeeze(0).transpose(0, 1)  # [N, C]
        scores_c_raw = scores_c.squeeze(0).transpose(0, 1)  # [N, 1]

        ####################################
        # 4. decoder part
        # NOTE: å‡ºäºæŸç§åŸå› ï¼Œ Decoder å¯¹ gnn è¾“å‡ºçš„ç‰¹å¾è¿›è¡Œäº†å½’ä¸€åŒ–
        src_feats_gnn, tgt_feats_gnn = feats_gnn_norm[:len_src_c], feats_gnn_norm[len_src_c:]
        # NOTE: ç‰¹å¾ç‚¹ç§¯è·å¾—ç›¸ä¼¼åº¦ (N1, C) @ (N2, C)^T -> (N_1, N_2)
        inner_products = torch.matmul(src_feats_gnn, tgt_feats_gnn.transpose(0, 1))

        src_scores_c, tgt_scores_c = scores_c_raw[:len_src_c], scores_c_raw[len_src_c:]

        # NOTE: åº”è¯¥æ˜¯å¯¹ç›¸ä¼¼åº¦çš„åˆ†å¸ƒè¿›è¡Œè°ƒæ•´ï¼Œå› ä¸º softmax å¯¹è¾ƒå¤§çš„è¾“å…¥å€¼æ— æ³•åŒºåˆ†
        temperature = torch.exp(self.epsilon) + 0.03
        # NOTE: F.softmax https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html
        # inner_products (N_1, N_2) ä»£è¡¨äº†ç‰¹å¾çš„ç›¸ä¼¼åº¦
        # Softmax å°†ç›¸ä¼¼åº¦è½¬åŒ–ä¸º 0-1 çš„æ¦‚ç‡åˆ†å¸ƒï¼Œæ²¿ç€ dim=1ï¼Œä¹Ÿå°±æ˜¯è¯´æ¯ä¸€è¡Œä¹‹å’Œä¸º 1
        # ä¸€è¡Œ N_2 ä¸ªæ•°ï¼Œä¸º tgt çš„ç‚¹æ•°ï¼Œä»£è¡¨äº†å½“å‰ src çš„ç‚¹æœ€æœ‰å¯èƒ½å’Œ tgt çš„å“ªä¸ªç‚¹åŒ¹é…
        # æœ€ååˆå’Œ tgt_scores_c è¿›è¡ŒçŸ©é˜µç›¸ä¹˜ï¼Œè·å¾—çš„ç»“æœå°±è¡¨ç¤ºäº†ï¼š**ç‰¹å¾ç›¸ä¼¼å¹¶ä¸”é‡å çš„æ¦‚ç‡**
        s1 = torch.matmul(F.softmax(inner_products / temperature, dim=1), tgt_scores_c)
        s2 = torch.matmul(F.softmax(inner_products.transpose(0, 1) / temperature, dim=1), src_scores_c)
        # NOTE: æ€»ç»“æ¥è¯´ï¼Œscores_saliency æ˜¯é€šè¿‡æ¨¡å‹é¢„æµ‹çš„ overlap score åŠ æƒå¾—åˆ°çš„ï¼Œæƒé‡æ¥è‡ªäº src å’Œ tgt æ¨¡å‹ç¼–ç ç‰¹å¾çš„ç›¸ä¼¼åº¦
        scores_saliency = torch.cat((s1, s2), dim=0)  # [N, 1]

        # NOTE: RECALL:
        # scores_c_raw          é‡å åˆ†æ•°
        # scores_saliency       åŒ¹é…åˆ†æ•°
        # feats_gnn_raw         ç»è¿‡ GNN çš„ç‚¹äº‘ç‰¹å¾
        # unconditioned_feats   æ²¡æœ‰ç»è¿‡ GNN çš„ç‰¹å¾ï¼ˆä¸åŒ…å«ä¸¤ä¸ªç‚¹äº‘ä¹‹é—´çš„å…³è”ï¼‰
        # NOTE: condition å«ä¹‰ç±»ä¼¼â€œå¯¹é½â€ï¼Œæ§åˆ¶æ˜¯å¦é€‰æ‹©ç”¨ attention æ¥è®©ä¸¤ä¸ªç‚¹äº‘çš„ç‰¹å¾äº¤äº’
        # NOTE: add_cross_overlap çš„å«ä¹‰åº”è¯¥æ˜¯ï¼Œæ˜¯å¦æŠŠåŒ¹é…åˆ†æ•°ï¼ˆcross overlap scoreï¼‰è¾“å‡ºåˆ°æœ€ç»ˆçš„ç‚¹äº‘ç‰¹å¾ä¸­
        # self.condition and self.add_cross_overlap:
        x = torch.cat([scores_c_raw, scores_saliency, feats_gnn_raw], dim=1)

        for block_i, block_op in enumerate(self.decoder_blocks):
            if block_i in self.decoder_concats:
                x = torch.cat([x, skip_x.pop()], dim=1)
            x = block_op(x, batch)
        feats_f = x[:, : self.final_feats_dim]
        scores_overlap = x[:, self.final_feats_dim]
        scores_saliency = x[:, self.final_feats_dim + 1]

        # safe guard our score
        sigmoid = nn.Sigmoid()
        scores_overlap = torch.clamp(sigmoid(scores_overlap.view(-1)), min=0, max=1)
        scores_saliency = torch.clamp(sigmoid(scores_saliency.view(-1)), min=0, max=1)
        scores_overlap = self.regular_score(scores_overlap)
        scores_saliency = self.regular_score(scores_saliency)

        # normalise point-wise features
        feats_f = F.normalize(feats_f, p=2, dim=1)

        source_superpoints = unconditioned_feats[:len_src_c]
        target_superpoints = unconditioned_feats[len_src_c:]
        return feats_f, scores_overlap, scores_saliency, source_superpoints, target_superpoints

    @torch.inference_mode()
    def encode(self, batch: Dict[str, List[torch.Tensor]]):
        # Get input features
        pcd = batch["points"][0]
        x = torch.ones((pcd.size(0), 1), dtype=torch.float32, device=pcd.device)

        #################################
        # 1. joint encoder part
        skip_x: List[torch.Tensor] = []
        for block_i, block_op in enumerate(self.encoder_blocks):
            if block_i in self.encoder_skips:
                skip_x.append(x)  # NOTE: ä¿å­˜å½“å‰å±‚è¾“å‡ºç”¨äº skip link
            x = block_op(x, batch)

        #################################
        # 2. project the bottleneck features
        feats_c = x.transpose(0, 1).unsqueeze(0)  # [1, C, N] # NOTE: è°ƒæ•´æ•°æ®ç»“æ„ä»¥é€‚ç”¨äº Conv1d
        feats_c = self.bottle(feats_c)  # [1, C, N]
        unconditioned_feats = feats_c.transpose(1, 2).squeeze(0)  # NOTE: æ²¡æœ‰ç»è¿‡ GNN çš„ç‰¹å¾ [N, C]

        skip_x.append(unconditioned_feats)
        # 4 length of features in each layer (N, C)
        assert len(skip_x) == 4
        return tuple(skip_x)  # jit recommend tuple

    @torch.inference_mode()
    def decode(self, batch: Dict[str, List[torch.Tensor]]):
        """
        batch['features'] å­˜å‚¨ encode çš„ç»“æœï¼Œå³æ¯å±‚ç‰¹å¾
        """
        skip_x = batch["features"][:3]
        unconditioned_feats = batch["features"][3]

        feats_c = unconditioned_feats.transpose(0, 1).unsqueeze(0)

        #################################
        # 3. apply GNN to communicate the features and get overlap score
        len_src_c = batch["stack_lengths"][-1][0]  # æœ€åä¸€å±‚ç‚¹äº‘é•¿åº¦
        src_feats_c, tgt_feats_c = feats_c[:, :, :len_src_c], feats_c[:, :, len_src_c:]
        # æœ€åä¸€å±‚ç‚¹äº‘åæ ‡
        pcd_c = batch["points"][-1]
        src_pcd_c, tgt_pcd_c = pcd_c[:len_src_c], pcd_c[len_src_c:]
        src_feats_c, tgt_feats_c = self.gnn(
            src_pcd_c.unsqueeze(0).transpose(1, 2),
            tgt_pcd_c.unsqueeze(0).transpose(1, 2),
            src_feats_c,
            tgt_feats_c,
        )
        feats_c = torch.cat([src_feats_c, tgt_feats_c], dim=-1)

        # NOTE: ä¸‹é¢è¿™ä¿©éƒ½æ˜¯ 1x1 å·ç§¯
        feats_c = self.proj_gnn(feats_c)  # æ²¡æœ‰æ”¹å˜ç»´åº¦ï¼Œå¯ä»¥å½“åš gnn è¾“å‡ºçš„æœ€ç»ˆç‰¹å¾ 256 (1, 256, N)
        scores_c = self.proj_score(feats_c)  # ç‰¹å¾ä» 256 åˆ° 1, ç”¨æ¥é¢„æµ‹ score (1, 1, N)

        feats_gnn_norm = (
            F.normalize(feats_c, p=2, dim=1).squeeze(0).transpose(0, 1)
        )  # [N, C], [N, 256] # NOTE: ç‰¹å¾çš„é€šé“è¿›è¡Œå½’ä¸€åŒ–å¤„ç†
        # NOTE: ğŸŒŸ GNN è¾“å‡ºç‰¹å¾
        feats_gnn_raw = feats_c.squeeze(0).transpose(0, 1)  # [N, C]
        scores_c_raw = scores_c.squeeze(0).transpose(0, 1)  # [N, 1]

        ####################################
        # 4. decoder part
        # NOTE: å‡ºäºæŸç§åŸå› ï¼Œ Decoder å¯¹ gnn è¾“å‡ºçš„ç‰¹å¾è¿›è¡Œäº†å½’ä¸€åŒ–
        src_feats_gnn, tgt_feats_gnn = feats_gnn_norm[:len_src_c], feats_gnn_norm[len_src_c:]
        # NOTE: ç‰¹å¾ç‚¹ç§¯è·å¾—ç›¸ä¼¼åº¦ (N1, C) @ (N2, C)^T -> (N_1, N_2)
        inner_products = torch.matmul(src_feats_gnn, tgt_feats_gnn.transpose(0, 1))

        src_scores_c, tgt_scores_c = scores_c_raw[:len_src_c], scores_c_raw[len_src_c:]

        # NOTE: åº”è¯¥æ˜¯å¯¹ç›¸ä¼¼åº¦çš„åˆ†å¸ƒè¿›è¡Œè°ƒæ•´ï¼Œå› ä¸º softmax å¯¹è¾ƒå¤§çš„è¾“å…¥å€¼æ— æ³•åŒºåˆ†
        temperature = torch.exp(self.epsilon) + 0.03
        # NOTE: F.softmax https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html
        # inner_products (N_1, N_2) ä»£è¡¨äº†ç‰¹å¾çš„ç›¸ä¼¼åº¦
        # Softmax å°†ç›¸ä¼¼åº¦è½¬åŒ–ä¸º 0-1 çš„æ¦‚ç‡åˆ†å¸ƒï¼Œæ²¿ç€ dim=1ï¼Œä¹Ÿå°±æ˜¯è¯´æ¯ä¸€è¡Œä¹‹å’Œä¸º 1
        # ä¸€è¡Œ N_2 ä¸ªæ•°ï¼Œä¸º tgt çš„ç‚¹æ•°ï¼Œä»£è¡¨äº†å½“å‰ src çš„ç‚¹æœ€æœ‰å¯èƒ½å’Œ tgt çš„å“ªä¸ªç‚¹åŒ¹é…
        # æœ€ååˆå’Œ tgt_scores_c è¿›è¡ŒçŸ©é˜µç›¸ä¹˜ï¼Œè·å¾—çš„ç»“æœå°±è¡¨ç¤ºäº†ï¼š**ç‰¹å¾ç›¸ä¼¼å¹¶ä¸”é‡å çš„æ¦‚ç‡**
        s1 = torch.matmul(F.softmax(inner_products / temperature, dim=1), tgt_scores_c)
        s2 = torch.matmul(F.softmax(inner_products.transpose(0, 1) / temperature, dim=1), src_scores_c)
        # NOTE: æ€»ç»“æ¥è¯´ï¼Œscores_saliency æ˜¯é€šè¿‡æ¨¡å‹é¢„æµ‹çš„ overlap score åŠ æƒå¾—åˆ°çš„ï¼Œæƒé‡æ¥è‡ªäº src å’Œ tgt æ¨¡å‹ç¼–ç ç‰¹å¾çš„ç›¸ä¼¼åº¦
        scores_saliency = torch.cat((s1, s2), dim=0)  # [N, 1]

        # NOTE: RECALL:
        # scores_c_raw          é‡å åˆ†æ•°
        # scores_saliency       åŒ¹é…åˆ†æ•°
        # feats_gnn_raw         ç»è¿‡ GNN çš„ç‚¹äº‘ç‰¹å¾
        # unconditioned_feats   æ²¡æœ‰ç»è¿‡ GNN çš„ç‰¹å¾ï¼ˆä¸åŒ…å«ä¸¤ä¸ªç‚¹äº‘ä¹‹é—´çš„å…³è”ï¼‰
        # NOTE: condition å«ä¹‰ç±»ä¼¼â€œå¯¹é½â€ï¼Œæ§åˆ¶æ˜¯å¦é€‰æ‹©ç”¨ attention æ¥è®©ä¸¤ä¸ªç‚¹äº‘çš„ç‰¹å¾äº¤äº’
        # NOTE: add_cross_overlap çš„å«ä¹‰åº”è¯¥æ˜¯ï¼Œæ˜¯å¦æŠŠåŒ¹é…åˆ†æ•°ï¼ˆcross overlap scoreï¼‰è¾“å‡ºåˆ°æœ€ç»ˆçš„ç‚¹äº‘ç‰¹å¾ä¸­
        # self.condition and self.add_cross_overlap:
        x = torch.cat([scores_c_raw, scores_saliency, feats_gnn_raw], dim=1)

        for block_i, block_op in enumerate(self.decoder_blocks):
            if block_i in self.decoder_concats:
                x = torch.cat([x, skip_x.pop()], dim=1)
            x = block_op(x, batch)
        feats_f = x[:, : self.final_feats_dim]
        scores_overlap = x[:, self.final_feats_dim]
        scores_saliency = x[:, self.final_feats_dim + 1]

        # safe guard our score
        sigmoid = nn.Sigmoid()
        scores_overlap = torch.clamp(sigmoid(scores_overlap.view(-1)), min=0, max=1)
        scores_saliency = torch.clamp(sigmoid(scores_saliency.view(-1)), min=0, max=1)
        scores_overlap = self.regular_score(scores_overlap)
        scores_saliency = self.regular_score(scores_saliency)

        # normalise point-wise features
        feats_f = F.normalize(feats_f, p=2, dim=1)

        return feats_f, scores_overlap, scores_saliency
